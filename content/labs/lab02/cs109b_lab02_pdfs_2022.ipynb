{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109B Data Science 2: Advanced Topics in Data Science \n",
    "\n",
    "## Lab 02 - Review of Probability Distributions \n",
    "\n",
    "**Harvard University**<br>\n",
    "**Spring 2022**<br>\n",
    "**Instructors:** Mark Glickman and Pavlos Protopapas<br>\n",
    "**Lab instructor and content:** Eleni Angelaki Kaxiras<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on PyMC3 v3.11.4\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "\n",
    "from pymc3 import summary\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "import warnings\n",
    "print('Running on PyMC3 v{}'.format(pm.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 20000;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas trick\n",
    "pd.options.display.max_columns = 50  # None -> No Restrictions\n",
    "pd.options.display.max_rows = 200    # None -> Be careful with this \n",
    "pd.options.display.max_colwidth = 100\n",
    "pd.options.display.precision = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A review of Common Probability Distributions\n",
    "\n",
    "### Discrete Distributions\n",
    "\n",
    "The random variable has a **probability mass function (pmf)** which measures the probability that our random variable will take a specific value $y$, denoted $P(Y=y)$.\n",
    "\n",
    "- **Bernoulli** (binary outcome, success has probability $\\theta$, $one$ trial):\n",
    "$\n",
    "P(Y=k) =  \\theta^k(1-\\theta)^{1-k}\n",
    "$\n",
    "<HR>\n",
    "- **Binomial** (binary outcome, success has probability $\\theta$, $k$ sucesses, $n$ trials):\n",
    "\\begin{equation}\n",
    "P(Y=k) =  {{n}\\choose{k}} \\cdot \\theta^k(1-\\theta)^{n-k}\n",
    "\\end{equation}\n",
    "\n",
    "*Note*: Binomial(1,$p$) = Bernouli($p$)\n",
    "<HR>\n",
    "- **Poisson** (counts independent events occurring at a rate $\\lambda$)\n",
    "\\begin{equation}\n",
    "P\\left( Y=y|\\lambda \\right) = \\frac{{e^{ - \\lambda } \\lambda ^y }}{{y!}}\n",
    "\\end{equation}\n",
    "y = 0,1,2,...\n",
    "<HR>\n",
    "- **Categorical, or Multinulli** (random variables can take any of K possible categories, each having its own probability; this is a generalization of the Bernoulli distribution for a discrete variable with more than two possible outcomes, such as the roll of a die)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Distributions\n",
    "\n",
    "The random variable has a **probability density function (pdf)**.\n",
    "- **Uniform** (variable equally likely to be near each value in interval $(a,b)$)\n",
    "\\begin{equation}\n",
    "P(X = x) = \\frac{1}{b - a}\n",
    "\\end{equation}\n",
    "anywhere within the interval $(a, b)$, and zero elsewhere.\n",
    "<HR>\n",
    "- **Normal** (a.k.a. Gaussian)\n",
    "\\begin{equation}\n",
    "X \\sim  \\mathcal{N}(\\mu,\\,\\sigma^{2})\n",
    "\\end{equation} \n",
    "\n",
    "    A Normal distribution can be parameterized either in terms of precision $\\tau$ or variance $\\sigma^{2}$. The link between the two is given by\n",
    "\\begin{equation}\n",
    "\\tau = \\frac{1}{\\sigma^{2}}\n",
    "\\end{equation}\n",
    " - Expected mean $\\mu$\n",
    " - Variance $\\frac{1}{\\tau}$ or $\\sigma^{2}$\n",
    " - Parameters: `mu: float`, `sigma: float` or `tau: float`\n",
    " - Range of values (-$\\infty$, $\\infty$)\n",
    "<HR>\n",
    "- **Beta** (where the variable ($\\theta$) takes on values in the interval $[0,1]$, and is parametrized by two positive parameters, $\\alpha$ and $\\beta$ that control the shape of the distribution. Note that Beta is a good distribution to use for priors (beliefs) because its range is $[0,1]$ which is the natural range for a probability and because we can model a wide range of functions by changing the $\\alpha$ and $\\beta$ parameters. Its density is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\label{eq:beta} \n",
    "P(\\theta|a,b) = \\frac{1}{B(\\alpha, \\beta)} {\\theta}^{\\alpha - 1} (1 - \\theta)^{\\beta - 1} \\propto {\\theta}^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}\n",
    "\\end{equation}\n",
    "\n",
    "where the normalisation constant, $B$, is a beta function of $\\alpha$ and $\\beta$,\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "B(\\alpha, \\beta) = \\int_{t=0}^1 t^{\\alpha - 1} (1 - t)^{\\beta - 1} dt.\n",
    "\\end{equation}\n",
    " - 'Nice', unimodal distribution\n",
    " - Range of values $[0, 1]$\n",
    "    \n",
    "<HR>\n",
    "    \n",
    "- **Exponential**\n",
    "    \n",
    " - Range of values [$0$, $\\infty$]\n",
    "<HR>\n",
    "- **Gamma**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Code Resources:\n",
    " - Statistical Distributions in numpy/scipy: [scipy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html)\n",
    " - Statistical Distributions in pyMC3: [distributions in PyMC3](https://docs.pymc.io/api/distributions.html) (we will see when we look at PyMC3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"discussion\"><b>Exercises: Discrete Probability Plots</b></div>\n",
    "\n",
    "#### Poisson\n",
    "Change the value of $\\lambda$ in the Poisson PMF and see how the plot changes. Remember that the y-axis in a discrete probability distribution shows the probability of the random variable having a specific value in the x-axis.\n",
    "\n",
    "\\begin{equation}\n",
    "P\\left( X=y \\right|\\lambda) = \\frac{{e^{ - \\lambda } \\lambda ^y }}{{y!}}\n",
    "\\end{equation}\n",
    "\n",
    "for $y \\ge0$.\n",
    "\n",
    "Routine is `stats.poisson.pmf(x, lambda)`. $\\lambda$ is our $\\theta$ in this case. $\\lambda$ is also the mean in this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-darkgrid')\n",
    "x = np.arange(0, 60)\n",
    "for lam in [0.5, 3, 8]:\n",
    "    pmf = stats.poisson.pmf(x, lam)\n",
    "    plt.plot(x, pmf, alpha=0.5, label='$\\lambda$ = {}'.format(lam))\n",
    "plt.xlabel('random variable', fontsize=12)\n",
    "plt.ylabel('probability', fontsize=12)\n",
    "plt.legend(loc=1)\n",
    "plt.ylim=(-0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-darkgrid')\n",
    "x = np.arange(0, 50)\n",
    "ns = [10, 17]\n",
    "ps = [0.5, 0.7]\n",
    "for n, p in zip(ns, ps):\n",
    "    pmf = stats.binom.pmf(x, n, p)\n",
    "    plt.plot(x, pmf, alpha=0.5, label='n = {}, p = {}'.format(n, p))\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('f(x)', fontsize=14)\n",
    "plt.legend(loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"discussion\"><b>Exercise: Continuous Distributions Plot<br></div>\n",
    "\n",
    "#### Uniform\n",
    "    \n",
    "Change the value of $\\mu$ in the Uniform PDF and see how the plot changes.\n",
    "    \n",
    "Remember that the y-axis in a continuous probability distribution does not shows the actual probability of the random variable having a specific value in the x-axis because that probability is zero!. Instead, to see the probability that the variable is within a small margin we look at the integral below the curve of the PDF.\n",
    "\n",
    "The uniform is often used as a noninformative prior.\n",
    "\n",
    "```\n",
    "Uniform - numpy.random.uniform(a=0.0, b=1.0, size)\n",
    "```\n",
    "\n",
    "$\\alpha$ and $\\beta$ are our parameters. `size` is how many tries to perform.\n",
    "Our $\\theta$ is basically the combination of the parameters a,b. We can also call it \n",
    "\\begin{equation}\n",
    "\\mu = (a+b)/2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "\n",
    "r = uniform.rvs(size=1000)\n",
    "plt.plot(r, uniform.pdf(r),'r-', lw=5, alpha=0.6, label='uniform pdf')\n",
    "plt.hist(r, density=True, histtype='stepfilled', alpha=0.2)\n",
    "plt.ylabel(r'probability density')\n",
    "plt.xlabel(f'random variable')\n",
    "plt.legend(loc='best', frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an amazing set of shapes by tweaking the two parameters $a$ and $b$! Notice that for $a=b=1.$ we get a constant. From then on, as the values increase, we get a curve that looks more and more Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "\n",
    "fontsize = 15\n",
    "alphas = [0.5, 0.5, 1., 3., 6.]\n",
    "betas = [0.5, 1., 1., 3., 6.]\n",
    "x = np.linspace(0, 1, 1000) \n",
    "colors = ['red', 'green', 'blue', 'black', 'pink']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "for a, b, colors in zip(alphas, betas, colors):\n",
    "    dist = beta(a, b)\n",
    "    plt.plot(x, dist.pdf(x), c=colors,\n",
    "             label=f'a={a}, b={b}')\n",
    "\n",
    "ax.set_ylim(0, 3)\n",
    "\n",
    "ax.set_xlabel(r'$\\theta$', fontsize=fontsize)\n",
    "ax.set_ylabel(r'P ($\\theta|\\alpha,\\beta)$', fontsize=fontsize)\n",
    "ax.set_title('Beta Distribution', fontsize=fontsize*1.2)\n",
    "\n",
    "ax.legend(loc='best')\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pm.Exponential.dist(lam=2), \n",
    "#y = pm.Binomial.dist(n=10, p=0.5)\n",
    "type(y)\n",
    "#print(y.logp(4).eval())\n",
    "#plt.plot(y.random(size=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-darkgrid')\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "mus = [0., 0., 0., -2.]\n",
    "sigmas = [0.4, 1., 2., 0.4]\n",
    "for mu, sigma in zip(mus, sigmas):\n",
    "    pdf = stats.norm.pdf(x, mu, sigma)\n",
    "    plt.plot(x, pdf, label=r'$\\mu$ = '+ f'{mu},' + r'$\\sigma$ = ' + f'{sigma}') \n",
    "plt.xlabel('random variable', fontsize=12)\n",
    "plt.ylabel('probability density', fontsize=12)\n",
    "plt.legend(loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"discussion\"> <b>At home</b>: Prove the formula mentioned in class which gives the probability density for a Beta distribution with parameters $2$ and $5$:<BR>\n",
    "$p(\\theta|2,5) = 30 \\cdot \\theta(1 - \\theta)^4$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**:\n",
    "\n",
    "- [Distributions in PyMC3](https://docs.pymc.io/api/distributions.html)\n",
    "\n",
    "Information about PyMC3 functions including descriptions of distributions, sampling methods, and other functions, is available via the `help` command."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
